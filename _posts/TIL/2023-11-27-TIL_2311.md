---
title: "23년 11월의 공부 - Docker image 지우기, TimeSeriesSplit, pd.Grouper, groupby with custom agg function"
categories: [TIL]
tags: [TIL]
toc : True
toc_sticky: true
math : True
last_modified_at: 2023-12-02
---

2023년 11월 동안 검색하고 공부한 것들을 정리한 내용입니다.   

## Docker image 지우기 
docker image를 삭제하는 방법은 두 가지를 알아보겠습니다.

### docker images -q & docker rmi
`docker images -q`를 통해 전체 image의 id를 확인할 수 있습니다. 해당 id 값을 통해 `docker rmi`를 통해 image를 삭제할 수 있습니다.

```bash
docker rmi $(docker images -q)
```

만약 실행되고 있는 docker container가 있다면 아래 명령어를 통해 container를 중지 또는 삭제 후 image를 삭제할 수 있습니다.

```bash
# To stop all running containers
docker container stop $(docker container ls -q)

# To remove all containers (including stopped ones)
docker container rm $(docker container ls -aq)
```

### docker system prune -a
`docker system prune`를 통해 전체 image, container, volume, network 등을 삭제할 수 있습니다.

```bash
docker system prune -a
```


## 시계열 데이터 Cross Validation
- 참고자료
    - [scikit-learn 공식문서 - model_selection.TimeSeriesSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html)

### 예제 데이터
예제로 사용할 데이터는 2022년 1월 1일부터 2023년 11월 30일까지 1일 단위 데이터를 생성합니다.  

```py
import numpy as np
import pandas as pd

df = pd.DataFrame(pd.date_range(start='2022-01-01', end='2023-11-30', freq='D'), columns=['timestamp'])
df = pd.concat([df, df], axis=0)
df['var1'] = np.arange(len(df))
```

### TimeSeriesSplit
`sklearn`의 `TimeSeriesSplit`은 데이터의 시간 순서를 보장하며 데이터를 분할하는 방법입니다. 일반적으로 진행하듯이 무작위로 데이터를 추출하는 것이 아니라, 아래와 같은 방식으로 train/test 데이터를 구분합니다.

    1. 전체 데이터를 n개의 동일한 길이로 나눔.
    2. 시작 시점부터 k(=1,2,...,n-1)개 그룹은 train 데이터, k+1 그룹은 test 데이터.


```py
from sklearn.model_selection import TimeSeriesSplit

tscv = TimeSeriesSplit(n_splits=5)
timestamp_pool = df['timestamp'].unique()

for train_index, test_index in tscv.split(timestamp_pool):
  train_ts = timestamp_pool[train_index]
  test_ts = timestamp_pool[test_index]

  print('Train: ', train_ts.min(), "~", train_ts.max())
  print('Test: ', test_ts.min(), "~", test_ts.max())
  print('='*80)

# Train:  2022-01-01T00:00:00.000000000 ~ 2022-04-29T00:00:00.000000000
# Test:  2022-04-30T00:00:00.000000000 ~ 2022-08-23T00:00:00.000000000
# ================================================================================
# Train:  2022-01-01T00:00:00.000000000 ~ 2022-08-23T00:00:00.000000000
# Test:  2022-08-24T00:00:00.000000000 ~ 2022-12-17T00:00:00.000000000
# ================================================================================
# Train:  2022-01-01T00:00:00.000000000 ~ 2022-12-17T00:00:00.000000000
# Test:  2022-12-18T00:00:00.000000000 ~ 2023-04-12T00:00:00.000000000
# ================================================================================
# Train:  2022-01-01T00:00:00.000000000 ~ 2023-04-12T00:00:00.000000000
# Test:  2023-04-13T00:00:00.000000000 ~ 2023-08-06T00:00:00.000000000
# ================================================================================
# Train:  2022-01-01T00:00:00.000000000 ~ 2023-08-06T00:00:00.000000000
# Test:  2023-08-07T00:00:00.000000000 ~ 2023-11-30T00:00:00.000000000
# ================================================================================
```

## pandas.Grouper
- 참고자료
    - [pandas 공식문서 - pandas.Grouper](https://pandas.pydata.org/docs/reference/api/pandas.Grouper.html)
    - [pandas 공식문서 - DateOffset aliases](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)

`pd.Grouper`를 이용하면 groupby의 key를 지정할 수 있습니다. 예를 들면, 1일 단위 데이터에 대해서 1년 단위 평균이나 6개월 단위의 평균을 계산할 수 있습니다.

```py
import numpy as np
import pandas as pd

df = pd.DataFrame(pd.date_range(start='2022-01-01', end='2023-11-30', freq='D'), columns=['timestamp'])
df = pd.concat([df, df], axis=0)
df['var1'] = np.arange(len(df))

df.groupby(pd.Grouper(key='timestamp', freq='1YS')).mean()
# timestamp	var1
# 2022-01-01	531.5
# 2023-01-01	881.0

df.groupby(pd.Grouper(key='timestamp', freq='6M')).mean()
# timestamp	var1
# 2022-01-31	364.5
# 2022-07-31	470.5
# 2023-01-31	653.0
# 2023-07-31	835.5
# 2024-01-31	987.0
```

## panads.groupby with custom aggregation function
`pandas`의 groupby 함수에서 사용자가 지정한 aggregation 함수를 사용할 수 있습니다.

```py
data = {'Category': ['A', 'B', 'A', 'B', 'A', 'B'],
        'Value': [10, 20, 30, 40, 50, 60]}
df = pd.DataFrame(data)

custom_aggregation = lambda x: pd.Series({'mean': x.mean(), 'std': x.std(), 'cv': x.mean()/x.std()})

result = df.groupby('Category')['Value'].apply(custom_aggregation).reset_index()
print(result)
#   Category level_1  Value
# 0        A    mean   30.0
# 1        A     std   20.0
# 2        A      cv    1.5
# 3        B    mean   40.0
# 4        B     std   20.0
# 5        B      cv    2.0
```

```py
result = pd.pivot_table(data=result, index='Category', values='Value', columns='level_1').reset_index()
result.columns.name = None
result
#   Category   cv  mean   std
# 0        A  1.5  30.0  20.0
# 1        B  2.0  40.0  20.0
```